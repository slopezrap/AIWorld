# ğŸ”§ Checklist de Refactoring â€” AIFoundry Backend

> **VersiÃ³n:** 1.0.0  
> **Fecha:** 2026-02-23  
> **Contexto:** Este checklist detalla las 4 grandes Ã¡reas de refactoring identificadas en la auditorÃ­a tÃ©cnica, diseÃ±adas para alinear el backend con la propuesta de frontend (`FRONTEND_DESIGN_PROPOSAL.md`) y preparar el sistema para producciÃ³n.

---

## Ãndice

1. [Refactorizar `agent.py`](#1-refactorizar-agentpy)
2. [AÃ±adir AutenticaciÃ³n](#2-aÃ±adir-autenticaciÃ³n)
3. [Implementar SSE/Streaming](#3-implementar-ssestreaming)
4. [Memoria Persistente](#4-memoria-persistente)

---

## 1. Refactorizar `agent.py`

> **Objetivo:** Descomponer el monolito `ConfigurableAgent` (~400 lÃ­neas) en mÃ³dulos cohesivos con responsabilidad Ãºnica. Esto facilita testing, mantenimiento y la futura integraciÃ³n de streaming.

### 1.1 AnÃ¡lisis y PreparaciÃ³n

- [x] **Mapear dependencias internas** del `ScraperAgent` actual:
  - Identificar los 4 bloques funcionales: memoria, tool resolving, parsing de output, orquestaciÃ³n principal.
  - Documentar quÃ© mÃ©todos llaman a quÃ© otros para entender el acoplamiento.
- [x] **Definir interfaces/contratos** para cada mÃ³dulo extraÃ­do:
  - `InMemoryManager` / `NullMemoryManager` â€” gestiÃ³n de memoria conversacional
  - `ToolResolver` â€” resoluciÃ³n de tools (MCP + locales)
  - `OutputParser` â€” extracciÃ³n de structured data y parsing de texto
  - `ScraperAgent` â€” orquestador (el nuevo `agent.py` reducido)
- [x] **Escribir tests del agente actual** (con LLM mockeado) ANTES de refactorizar (46 tests en `test_scraper_agent.py`):
  - Test de `run()` con respuesta simple (sin tools)
  - Test de `run()` con structured output nativo
  - Test de `run()` con structured output legacy (fallback)
  - Test de retry en error recuperable
  - Test de error no recuperable
  - Test de memoria conversacional (multi-turn)

### 1.2 ExtracciÃ³n del MÃ³dulo de Memoria (`memory.py`)

- [x] Crear `aifoundry/app/core/agents/scraper/memory.py`
- [x] Extraer de `agent.py`:
  - Checkpointer de LangGraph â†’ clase `InMemoryManager`
  - Thread ID management â†’ `generate_thread_id()`
  - History access â†’ `get_history()`
  - Session clearing â†’ `clear_session()`
- [x] Implementar `InMemoryManager` â€” con `MemorySaver` de LangGraph
- [x] Implementar `NullMemoryManager` â€” para agentes sin memoria
- [x] Actualizar `agent.py` para usar `InMemoryManager`/`NullMemoryManager`
- [x] Tests unitarios: 11 tests en `test_memory.py`
- [x] Verificar que todos los tests pasan (206 âœ…)
- [ ] **Futuro:** Reemplazar cleanup por background task periÃ³dico en `lifespan`

### 1.3 ExtracciÃ³n del Tool Resolver (`tool_executor.py`)

- [x] Crear `aifoundry/app/core/agents/scraper/tool_executor.py`
- [x] Extraer de `agent.py`:
  - `get_mcp_configs()` â†’ mÃ©todo interno de `ToolResolver`
  - `get_local_tools()` â†’ mÃ©todo `_get_local_tools()`
  - ConexiÃ³n MCP via `MultiServerMCPClient` â†’ `_resolve_mcp_tools()`
  - Cleanup de MCP clients â†’ `cleanup()`
- [x] Definir clase `ToolResolver`:
  ```python
  class ToolResolver:
      async def resolve_tools(self) -> list[BaseTool]
      async def cleanup() -> None
  ```
- [x] Manejo graceful de fallos MCP (continÃºa solo con tools locales)
- [x] Actualizar `agent.py` para usar `ToolResolver` inyectado
- [x] Tests unitarios: 15 tests en `test_tool_executor.py` con MCP mockeado
- [x] Verificar que todos los tests pasan (221 âœ…)
- [ ] **Futuro:** Pool/cache de conexiones MCP
- [ ] **Futuro:** Eventos/callbacks en la ejecuciÃ³n de tools para streaming

### 1.4 ExtracciÃ³n del Phase Runner (`phase_runner.py`)

> **Nota:** El agente actual usa un flujo ReAct (no fases secuenciales), asÃ­ que no se necesita un `PhaseRunner` separado. La lÃ³gica de retry y ejecuciÃ³n estÃ¡ en `ScraperAgent.run()`. Se reconsiderarÃ¡ si se implementa ejecuciÃ³n multi-fase.

- [ ] **Futuro:** Si se implementan fases secuenciales, extraer a `phase_runner.py`
- [ ] **Futuro:** Eventos/callbacks por fase para streaming

### 1.5 ExtracciÃ³n del Output Parser (`output_parser.py`)

- [x] Crear `aifoundry/app/core/agents/scraper/output_parser.py`
- [x] Extraer de `agent.py`:
  - `_convert_to_structured()` â†’ `OutputParser.extract_structured()`
  - `parse_output()` â†’ `OutputParser.parse_text()`
  - LÃ³gica de structured output nativo vs legacy (fallback)
- [x] Definir clase `OutputParser`:
  ```python
  class OutputParser:
      async def extract_structured(result, output, llm, config) -> BaseModel | None
      def parse_text(output: str) -> dict
  ```
- [x] Tests unitarios: 9 tests en `test_output_parser.py`
- [x] Verificar que todos los tests pasan (230 âœ…)

### 1.6 Agente Orquestador Simplificado (`agent.py` refactorizado)

- [x] `ScraperAgent` ahora orquesta 3 mÃ³dulos:
  1. `InMemoryManager` / `NullMemoryManager` â€” gestiÃ³n de memoria
  2. `ToolResolver` â€” resoluciÃ³n de tools (MCP + locales)
  3. `OutputParser` â€” structured output + text parsing
- [x] El constructor inyecta las 3 dependencias
- [x] `run()` delega a `OutputParser.extract_structured()` y `OutputParser.parse_text()`
- [x] `initialize()` delega a `ToolResolver.resolve_tools()`
- [x] `cleanup()` delega a `ToolResolver.cleanup()`
- [x] Verificar que TODOS los tests pasan (230 âœ…)
- **Nota:** `agent.py` tiene ~607 lÃ­neas (incluyendo `AgentCallbackHandler` ~90 lÃ­neas, error helpers ~50 lÃ­neas, docstrings extensos). El cÃ³digo de orquestaciÃ³n real del `ScraperAgent` es ~250 lÃ­neas.

### 1.7 ActualizaciÃ³n de DocumentaciÃ³n

- [x] Actualizar `docs/REFACTORING_CHECKLIST.md` con el estado actual
- [ ] Actualizar `docs/AGENTS.md` con la nueva estructura modular
- [ ] Documentar las interfaces/protocolos para contribuidores

---

## 2. AÃ±adir AutenticaciÃ³n

> **Objetivo:** Proteger los endpoints con API key, alineado con lo que el frontend necesitarÃ¡. El `FRONTEND_DESIGN_PROPOSAL.md` asume comunicaciÃ³n directa backendâ†”frontend, por lo que la auth debe ser ligera pero segura.

### 2.1 DiseÃ±o

- [ ] **Elegir mecanismo:** API Key en header `X-API-Key` (simple, suficiente para Phase 1 del frontend)
  - Futuro: OAuth2/JWT para multi-usuario (Phase 2+)
- [ ] **Definir configuraciÃ³n:**
  ```env
  # .env
  API_KEYS=key1,key2,key3          # Lista de API keys vÃ¡lidas (comma-separated)
  AUTH_ENABLED=true                  # Toggle para desarrollo local
  ```
- [ ] **Definir quÃ© endpoints proteger:**
  - `GET /api/health` â†’ âŒ NO proteger (necesario para health checks de Docker/K8s)
  - `GET /api/agents` â†’ âœ… Proteger
  - `GET /api/agents/{name}/config` â†’ âœ… Proteger
  - `POST /api/agents/{name}/chat` â†’ âœ… Proteger
  - `DELETE /api/agents/{name}/sessions/{id}` â†’ âœ… Proteger
  - Futuro `GET /api/agents/{name}/stream` â†’ âœ… Proteger

### 2.2 ImplementaciÃ³n

- [ ] AÃ±adir `api_keys` y `auth_enabled` a `config.py` (`Settings`):
  ```python
  api_keys: list[str] = []       # Si vacÃ­o, auth deshabilitada
  auth_enabled: bool = False     # Toggle explÃ­cito
  ```
- [ ] Crear `aifoundry/app/api/auth.py`:
  ```python
  from fastapi import Security, HTTPException, status
  from fastapi.security import APIKeyHeader
  
  api_key_header = APIKeyHeader(name="X-API-Key", auto_error=False)
  
  async def verify_api_key(api_key: str = Security(api_key_header)) -> str:
      if not settings.auth_enabled:
          return "development"
      if api_key not in settings.api_keys:
          raise HTTPException(status_code=401, detail="API key invÃ¡lida o ausente")
      return api_key
  ```
- [ ] Aplicar como dependencia en `router.py`:
  ```python
  router = APIRouter(prefix="/api", dependencies=[Depends(verify_api_key)])
  ```
  - Excepto `/health` que debe estar fuera del router protegido o tener su propio router sin auth
- [ ] Actualizar `.env.example` con las nuevas variables
- [ ] Actualizar `docker-compose.yml` para pasar las variables de entorno

### 2.3 Testing

- [ ] Test: Request sin API key â†’ 401
- [ ] Test: Request con API key invÃ¡lida â†’ 401
- [ ] Test: Request con API key vÃ¡lida â†’ 200
- [ ] Test: `/health` sin API key â†’ 200 (no protegido)
- [ ] Test: `auth_enabled=false` â†’ todas las requests pasan sin key

### 2.4 DocumentaciÃ³n

- [ ] Actualizar `README.md` con instrucciones de autenticaciÃ³n
- [ ] Documentar en la secciÃ³n de API de `AGENTS.md`
- [ ] AÃ±adir header `X-API-Key` a la documentaciÃ³n OpenAPI (FastAPI lo harÃ¡ automÃ¡ticamente via `APIKeyHeader`)

---

## 3. Implementar SSE/Streaming

> **Objetivo:** Reemplazar el endpoint sÃ­ncrono `POST /chat` con un sistema de streaming basado en SSE (Server-Sent Events), alineado con el **Phase 2** del `FRONTEND_DESIGN_PROPOSAL.md`. Esto elimina el cuello de botella del request bloqueante y habilita la UX de "pensamiento en vivo" tipo Cline.

### 3.1 DiseÃ±o del Protocolo SSE

> Referencia: `FRONTEND_DESIGN_PROPOSAL.md` secciÃ³n "Streaming Protocol"

- [ ] **Definir tipos de evento SSE:**
  ```
  event: thinking        â†’ data: {"content": "Analizando la consulta..."}
  event: phase_start     â†’ data: {"phase_id": "search", "description": "Buscando informaciÃ³n"}
  event: tool_start      â†’ data: {"tool": "brave_search", "arguments": {"query": "..."}}
  event: tool_result     â†’ data: {"tool": "brave_search", "result": "...", "success": true}
  event: text            â†’ data: {"content": "Fragmento de respuesta..."}  (token streaming)
  event: structured_data â†’ data: {"schema": "ElectricityResponse", "data": {...}}
  event: phase_complete  â†’ data: {"phase_id": "search", "summary": "..."}
  event: done            â†’ data: {"metadata": {"duration_ms": 1234, "model": "gpt-4o-mini", ...}}
  event: error           â†’ data: {"code": "LLM_ERROR", "message": "..."}
  ```
- [ ] **Definir schemas Pydantic** para cada tipo de evento en `aifoundry/app/api/schemas.py`:
  ```python
  class SSEEvent(BaseModel):
      event: str
      data: dict
  
  class ThinkingEvent(BaseModel): ...
  class ToolStartEvent(BaseModel): ...
  class ToolResultEvent(BaseModel): ...
  # etc.
  ```

### 3.2 Sistema de Eventos Interno

- [ ] Crear `aifoundry/app/core/agents/scraper/events.py`:
  - Definir `AgentEvent` (union type de todos los eventos posibles)
  - Definir `EventEmitter` â€” interfaz para emitir eventos durante la ejecuciÃ³n:
    ```python
    class EventEmitter(Protocol):
        async def emit(self, event: AgentEvent) -> None
    
    class AsyncQueueEmitter(EventEmitter):
        """Emite eventos a un asyncio.Queue para consumo por SSE."""
        def __init__(self):
            self.queue: asyncio.Queue[AgentEvent] = asyncio.Queue()
        
        async def emit(self, event: AgentEvent) -> None:
            await self.queue.put(event)
        
        async def events(self) -> AsyncGenerator[AgentEvent, None]:
            while True:
                event = await self.queue.get()
                if event.event == "done":
                    yield event
                    break
                yield event
    ```
- [ ] Integrar `EventEmitter` en los mÃ³dulos refactorizados:
  - `ToolExecutor.execute()` â†’ emite `tool_start` y `tool_result`
  - `PhaseRunner.run_single_phase()` â†’ emite `phase_start`, `thinking`, `phase_complete`
  - `OutputParser.parse()` â†’ emite `structured_data`
  - `ConfigurableAgent.chat()` â†’ emite `done` o `error`

### 3.3 Endpoint SSE

- [ ] Crear nuevo endpoint `POST /api/agents/{name}/stream` en `router.py`:
  ```python
  from sse_starlette.sse import EventSourceResponse
  
  @router.post("/agents/{agent_name}/stream")
  async def stream_agent(agent_name: str, request: ChatRequest):
      emitter = AsyncQueueEmitter()
      
      # Lanzar ejecuciÃ³n del agente en background
      async def run_agent():
          try:
              await agent.chat(query=request.query, ..., event_emitter=emitter)
          except Exception as e:
              await emitter.emit(ErrorEvent(message=str(e)))
      
      asyncio.create_task(run_agent())
      
      # Devolver stream SSE
      async def event_generator():
          async for event in emitter.events():
              yield {"event": event.event, "data": event.model_dump_json()}
      
      return EventSourceResponse(event_generator())
  ```
- [ ] AÃ±adir dependencia `sse-starlette` al `pyproject.toml`
- [ ] **Mantener el endpoint `/chat` sÃ­ncrono** como fallback para clientes simples (scripts, testing)
- [ ] Implementar timeout global para el stream (ej: 5 minutos mÃ¡ximo)

### 3.4 Token Streaming del LLM

- [ ] Modificar `llm.py` para soportar streaming:
  ```python
  async def acompletion_stream(self, messages, **kwargs) -> AsyncGenerator[str, None]:
      response = await litellm.acompletion(messages=messages, stream=True, **kwargs)
      async for chunk in response:
          delta = chunk.choices[0].delta.content
          if delta:
              yield delta
  ```
- [ ] Integrar con `PhaseRunner` para emitir eventos `text` por cada chunk
- [ ] **Nota:** Cuando hay tool calling, el LLM no streama texto sino tool calls. Manejar ambos flujos.

### 3.5 Compatibilidad con FRONTEND_DESIGN_PROPOSAL.md

- [ ] Verificar que los nombres de eventos SSE coinciden con los esperados por el frontend:
  - `thinking`, `tool_start`, `tool_result`, `text`, `structured_data`, `done`
- [ ] El endpoint debe aceptar el mismo `ChatRequest` body que `/chat`
- [ ] El evento `done` debe incluir los mismos `metadata` que la respuesta sÃ­ncrona actual
- [ ] Verificar CORS headers para SSE (`text/event-stream`)

### 3.6 Testing

- [ ] Test unitario: `AsyncQueueEmitter` emite y consume eventos correctamente
- [ ] Test de integraciÃ³n: `/stream` devuelve `Content-Type: text/event-stream`
- [ ] Test de integraciÃ³n: El stream emite al menos `thinking` â†’ `done`
- [ ] Test de error: Si el agente falla, se emite evento `error` y el stream se cierra
- [ ] Test de timeout: Si el agente excede el timeout, se emite error y se cierra
- [ ] **Load test bÃ¡sico:** 10 requests concurrentes de streaming no crashean el servidor

### 3.7 DocumentaciÃ³n

- [ ] Actualizar `FRONTEND_DESIGN_PROPOSAL.md` para reflejar el endpoint real (`/stream` en lugar de `/run`)
- [ ] Documentar el protocolo SSE en un nuevo `docs/STREAMING.md`
- [ ] AÃ±adir ejemplos de consumo SSE con `curl` y `EventSource` (JS)

---

## 4. Memoria Persistente

> **Objetivo:** Reemplazar el `dict` en memoria por un almacenamiento persistente que sobreviva reinicios y soporte escalado horizontal. El `FRONTEND_DESIGN_PROPOSAL.md` asume sesiones multi-turno, por lo que la persistencia es crÃ­tica.

### 4.1 EvaluaciÃ³n de Opciones

- [ ] **Evaluar y decidir** entre las opciones:

  | OpciÃ³n | Pros | Contras | Recomendada para |
  |--------|------|---------|-----------------|
  | **SQLite** | Sin infra extra, persistente, incluido en Python | No escala horizontal, lock en escritura | Desarrollo / Single instance |
  | **Redis** | RÃ¡pido, TTL nativo, escala horizontal | Requiere infra extra (Docker service) | ProducciÃ³n / Multi-instance |
  | **PostgreSQL** | Robusto, transaccional, ya estÃ¡ndar en empresas | MÃ¡s complejo, overhead para K/V simple | Si ya existe en la infra |

  **RecomendaciÃ³n:** Implementar **Redis como primary** (producciÃ³n) con **SQLite como fallback** (desarrollo sin Docker).

### 4.2 Interfaz Abstracta (ya definida en 1.2)

- [ ] Confirmar que `BaseMemoryManager` del refactoring del agente soporta las operaciones necesarias:
  ```python
  class BaseMemoryManager(Protocol):
      async def get_messages(self, session_id: str) -> list[dict]
      async def add_message(self, session_id: str, role: str, content: str) -> None
      async def clear_session(self, session_id: str) -> None
      async def cleanup_expired(self) -> int
      async def list_sessions(self, agent_id: str) -> list[SessionInfo]  # NUEVO
      async def get_session_metadata(self, session_id: str) -> SessionMetadata | None  # NUEVO
  ```
- [ ] Definir `SessionInfo` y `SessionMetadata`:
  ```python
  class SessionMetadata(BaseModel):
      session_id: str
      agent_id: str
      created_at: datetime
      last_active: datetime
      message_count: int
      ttl_minutes: int
  ```

### 4.3 ImplementaciÃ³n Redis (`redis_memory.py`)

- [ ] Crear `aifoundry/app/core/agents/scraper/redis_memory.py`
- [ ] Implementar `RedisMemoryManager(BaseMemoryManager)`:
  - **Estructura de datos Redis:**
    ```
    session:{session_id}:messages  â†’ LIST de JSON strings (cada mensaje)
    session:{session_id}:metadata  â†’ HASH (agent_id, created_at, last_active, ttl)
    agent:{agent_id}:sessions      â†’ SET de session_ids
    ```
  - TTL nativo de Redis en las keys de sesiÃ³n
  - `LTRIM` para respetar `max_messages`
- [ ] AÃ±adir dependencia `redis[hiredis]` al `pyproject.toml`
- [ ] AÃ±adir configuraciÃ³n a `config.py`:
  ```python
  redis_url: str = "redis://localhost:6379/0"
  memory_backend: Literal["memory", "redis", "sqlite"] = "memory"
  ```
- [ ] AÃ±adir servicio Redis al `docker-compose.yml`:
  ```yaml
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
  ```

### 4.4 ImplementaciÃ³n SQLite (`sqlite_memory.py`)

- [ ] Crear `aifoundry/app/core/agents/scraper/sqlite_memory.py`
- [ ] Implementar `SQLiteMemoryManager(BaseMemoryManager)`:
  - **Schema:**
    ```sql
    CREATE TABLE sessions (
        session_id TEXT PRIMARY KEY,
        agent_id TEXT NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        ttl_minutes INTEGER DEFAULT 30
    );
    CREATE TABLE messages (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        session_id TEXT NOT NULL REFERENCES sessions(session_id),
        role TEXT NOT NULL,
        content TEXT NOT NULL,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    CREATE INDEX idx_messages_session ON messages(session_id);
    ```
  - Usar `aiosqlite` para operaciones async
  - Cleanup de sesiones expiradas via `DELETE WHERE last_active + ttl < now()`
- [ ] AÃ±adir dependencia `aiosqlite` al `pyproject.toml`
- [ ] DB file en ruta configurable: `sqlite_db_path: str = "data/memory.db"`

### 4.5 Factory de Memoria

- [ ] Crear factory en `aifoundry/app/core/agents/scraper/memory.py`:
  ```python
  def create_memory_manager(backend: str, config: Settings) -> BaseMemoryManager:
      match backend:
          case "memory":
              return InMemoryManager()
          case "redis":
              return RedisMemoryManager(redis_url=config.redis_url)
          case "sqlite":
              return SQLiteMemoryManager(db_path=config.sqlite_db_path)
          case _:
              raise ValueError(f"Backend de memoria no soportado: {backend}")
  ```
- [ ] Instanciar en el `lifespan` de `main.py` y compartir vÃ­a `app.state`
- [ ] Inyectar en los agentes al crearlos

### 4.6 MigraciÃ³n de Datos

- [ ] El `InMemoryManager` existente debe seguir funcionando sin cambios (backward compatible)
- [ ] AÃ±adir script de migraciÃ³n `scripts/migrate_memory.py` (por si en futuro se cambia de backend)
- [ ] Documentar el proceso de cambio de backend

### 4.7 Background Tasks

- [ ] Registrar tarea periÃ³dica de cleanup en el `lifespan`:
  ```python
  async def periodic_cleanup(memory: BaseMemoryManager):
      while True:
          await asyncio.sleep(60)  # cada minuto
          cleaned = await memory.cleanup_expired()
          if cleaned > 0:
              logger.info(f"ğŸ§¹ Cleaned {cleaned} expired sessions")
  ```
- [ ] La tarea debe cancelarse limpiamente en el shutdown

### 4.8 Testing

- [ ] Test unitario: `InMemoryManager` â€” CRUD de mensajes, TTL, cleanup
- [ ] Test unitario: `RedisMemoryManager` â€” usar `fakeredis` para mock
- [ ] Test unitario: `SQLiteMemoryManager` â€” usar DB temporal en `/tmp`
- [ ] Test de integraciÃ³n: Reiniciar servidor â†’ las sesiones persisten (Redis/SQLite)
- [ ] Test de integraciÃ³n: MÃºltiples workers comparten la misma memoria (Redis)
- [ ] Test de concurrencia: Escrituras simultÃ¡neas no corrompen datos

### 4.9 DocumentaciÃ³n

- [ ] Actualizar `README.md` con opciones de backend de memoria
- [ ] Actualizar `docker-compose.yml` documentation
- [ ] Documentar variables de entorno nuevas en `.env.example`
- [ ] Actualizar `FRONTEND_DESIGN_PROPOSAL.md` secciÃ³n de sesiones para reflejar la persistencia

---

## ğŸ“‹ Orden de EjecuciÃ³n Recomendado

```
Fase 1 (Fundamentos):
  1.1-1.7  Refactorizar agent.py          â† Primero, porque todo lo demÃ¡s depende de esto
  
Fase 2 (Seguridad + Persistencia, en paralelo):
  2.1-2.4  AutenticaciÃ³n                  â† Independiente, se puede hacer en paralelo
  4.1-4.9  Memoria Persistente            â† Depende del refactoring de memoria (1.2)
  
Fase 3 (Streaming):
  3.1-3.7  SSE/Streaming                  â† Depende del sistema de eventos (1.3, 1.4)
```

### Dependencias entre tareas:

```
[1. Refactoring agent.py]
    â”œâ”€â”€ [1.2 Memoria] â”€â”€â”€â”€â”€â”€â†’ [4. Memoria Persistente]
    â”œâ”€â”€ [1.3 ToolExecutor] â”€â”€â†’ [3. SSE/Streaming (eventos de tools)]
    â”œâ”€â”€ [1.4 PhaseRunner] â”€â”€â”€â†’ [3. SSE/Streaming (eventos de fases)]
    â””â”€â”€ [1.6 Orquestador] â”€â”€â†’ [3. SSE/Streaming (endpoint)]

[2. AutenticaciÃ³n] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (independiente, se aplica a todos los endpoints)
```

---

## ğŸ“Š MÃ©tricas de Ã‰xito

| MÃ©trica | Antes | DespuÃ©s |
|---------|-------|---------|
| LÃ­neas en `agent.py` | ~400 | ~607 (orquestaciÃ³n ~250, callback ~90, helpers ~50, docs ~200) |
| MÃ³dulos en `base/` | 4 archivos | 8 archivos (`agent.py`, `memory.py`, `tool_executor.py`, `output_parser.py`, `config_schema.py`, `prompts.py`, `tools.py`, `__init__.py`) |
| Test coverage del agente | 0% | 230 tests (46 agent + 11 memory + 15 tool_executor + 9 output_parser + 149 otros) |
| Tiempo de respuesta API | Bloqueante (30s+) | Primer evento SSE <1s |
| Sesiones tras reinicio | Perdidas | Persistentes |
| Endpoints protegidos | 0 | Todos (excepto health) |